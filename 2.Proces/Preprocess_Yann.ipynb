{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fc79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (160000, 41)\n",
      "Test shape:  (40000, 40)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# =========================\n",
    "# 1. Chargement des données\n",
    "# =========================\n",
    "df_train = pd.read_csv(\"../6.Data/kaggle_b2_fraud_train_v3.csv\")\n",
    "df_test  = pd.read_csv(\"../6.Data/kaggle_b2_fraud_test_v3.csv\")  # pas de colonne target\n",
    "\n",
    "# =========================\n",
    "# 2. Suppression colonnes inutiles\n",
    "# =========================\n",
    "cols_to_drop = [\n",
    "    \"account_id\", \"city\", \"postal_code\",\n",
    "    \"chargeback_resolution_time_days\", \"post_event_status_code\",\n",
    "    \"referrer_code\", \"manual_review_result\", \"terms_accepted_flag\",\n",
    "    \"occupation\", \"merchant_category\", \"customer_note\",\n",
    "    \"last_ticket_subject\", \"region\", \"country\", \"signup_source\"\n",
    "]\n",
    "df_train = df_train.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "df_test  = df_test.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# 3. Imputation des valeurs manquantes\n",
    "# (paramètres calculés sur train uniquement)\n",
    "# =========================\n",
    "median_cols = [\"annual_income_eur\", \"credit_score\", \"avg_amount_30d_eur\", \"max_amount_30d_eur\"]\n",
    "median_values = df_train[median_cols].median()  # ← appris sur train\n",
    "for col in median_cols:\n",
    "    df_train[col] = df_train[col].fillna(median_values[col])\n",
    "    df_test[col]  = df_test[col].fillna(median_values[col])\n",
    "\n",
    "mean_cols = [\"device_trust_z\", \"ip_risk_z\"]\n",
    "mean_values = df_train[mean_cols].mean()  # ← appris sur train\n",
    "for col in mean_cols:\n",
    "    df_train[col] = df_train[col].fillna(mean_values[col])\n",
    "    df_test[col]  = df_test[col].fillna(mean_values[col])\n",
    "\n",
    "# Booléen présence secondary_email\n",
    "df_train[\"secondary_email\"] = df_train[\"secondary_email\"].notna().astype(int)\n",
    "df_test[\"secondary_email\"]  = df_test[\"secondary_email\"].notna().astype(int)\n",
    "\n",
    "# Valeurs legacy\n",
    "df_train[\"legacy_partner_score\"]    = df_train[\"legacy_partner_score\"].fillna(0)\n",
    "df_train[\"partner_risk_indicator\"]  = df_train[\"partner_risk_indicator\"].fillna(0)\n",
    "df_test[\"legacy_partner_score\"]     = df_test[\"legacy_partner_score\"].fillna(0)\n",
    "df_test[\"partner_risk_indicator\"]   = df_test[\"partner_risk_indicator\"].fillna(0)\n",
    "\n",
    "# =========================\n",
    "# 4. Encodage catégoriel\n",
    "# =========================\n",
    "# One-hot : plan_type (align sur les colonnes du train)\n",
    "plan_dummies_train = pd.get_dummies(df_train[\"plan_type\"], prefix=\"plan_type\")\n",
    "plan_dummies_test  = pd.get_dummies(df_test[\"plan_type\"],  prefix=\"plan_type\")\n",
    "plan_dummies_test  = plan_dummies_test.reindex(columns=plan_dummies_train.columns, fill_value=0)\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns=[\"plan_type\"]), plan_dummies_train], axis=1)\n",
    "df_test  = pd.concat([df_test.drop(columns=[\"plan_type\"]),  plan_dummies_test],  axis=1)\n",
    "\n",
    "# One-hot : channel\n",
    "channel_dummies_train = pd.get_dummies(df_train[\"channel\"], prefix=\"channel\")\n",
    "channel_dummies_test  = pd.get_dummies(df_test[\"channel\"],  prefix=\"channel\")\n",
    "channel_dummies_test  = channel_dummies_test.reindex(columns=channel_dummies_train.columns, fill_value=0)\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns=[\"channel\"]), channel_dummies_train], axis=1)\n",
    "df_test  = pd.concat([df_test.drop(columns=[\"channel\"]),  channel_dummies_test],  axis=1)\n",
    "\n",
    "# Booléens\n",
    "binary_cols = [\"is_vpn\", \"is_new_device\"]\n",
    "for col in binary_cols:\n",
    "    df_train[col] = df_train[col].astype(int)\n",
    "    df_test[col]  = df_test[col].astype(int)\n",
    "\n",
    "# Target encoding : mapping calculé sur le TRAIN uniquement\n",
    "target_cols = [\"payment_method\", \"browser\", \"os\", \"device_type\"]\n",
    "target_encodings = {}  # on sauvegarde les mappings\n",
    "for col in target_cols:\n",
    "    mapping = df_train.groupby(col)[\"target_is_fraud\"].mean()\n",
    "    target_encodings[col] = mapping\n",
    "    df_train[col] = df_train[col].map(mapping)\n",
    "    # Pour le test : catégories inconnues → moyenne globale du train (fallback)\n",
    "    global_mean = df_train[\"target_is_fraud\"].mean()\n",
    "    df_test[col] = df_test[col].map(mapping).fillna(global_mean)\n",
    "\n",
    "# =========================\n",
    "# 5. Feature engineering dates\n",
    "# =========================\n",
    "today = pd.Timestamp.today()  # une seule référence pour train et test\n",
    "\n",
    "df_train[\"signup_date\"] = pd.to_datetime(df_train[\"signup_date\"])\n",
    "df_train[\"account_age_days\"] = (today - df_train[\"signup_date\"]).dt.days\n",
    "\n",
    "df_test[\"signup_date\"] = pd.to_datetime(df_test[\"signup_date\"])\n",
    "df_test[\"account_age_days\"] = (today - df_test[\"signup_date\"]).dt.days\n",
    "\n",
    "cols_to_drop_post = [\n",
    "    \"signup_date\", \"payment_method\", \"browser\", \"os\", \"device_type\",\n",
    "    \"is_vpn\", \"is_new_device\"\n",
    "]\n",
    "df_train = df_train.drop(columns=cols_to_drop_post)\n",
    "df_test  = df_test.drop(columns=cols_to_drop_post)\n",
    "\n",
    "# =========================\n",
    "# 6. Traitement outliers\n",
    "# (quantiles calculés sur train uniquement)\n",
    "# =========================\n",
    "log_clip_cols = [\n",
    "    \"chargebacks_12m\", \"days_since_last_login\", \"tenure_months\",\n",
    "    \"max_amount_30d_eur\", \"income_estimate_alt_eur\", \"tx_amount_total_30d_eur\",\n",
    "    \"annual_income_eur\", \"avg_amount_30d_eur\", \"num_devices_30d\",\n",
    "    \"support_tickets_90d\", \"failed_payments_6m\", \"age\", \"credit_score\"\n",
    "]\n",
    "clip_bounds = {}\n",
    "for col in log_clip_cols:\n",
    "    lower = df_train[col].quantile(0.01)\n",
    "    upper = df_train[col].quantile(0.99)\n",
    "    clip_bounds[col] = (lower, upper)\n",
    "    df_train[col] = df_train[col].clip(lower, upper)\n",
    "    df_test[col]  = df_test[col].clip(lower, upper)\n",
    "\n",
    "# =========================\n",
    "# 7. Standardisation finale\n",
    "# (scaler fitté sur train uniquement)\n",
    "# =========================\n",
    "numeric_cols = df_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "numeric_cols = numeric_cols.drop(\"target_is_fraud\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_train[numeric_cols] = scaler.fit_transform(df_train[numeric_cols])   # fit + transform\n",
    "df_test[numeric_cols]  = scaler.transform(df_test[numeric_cols])         # transform only ✓\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 8. transformer les colonnes booléennes (True / False) en numériques (1 / 0)\n",
    "# =========================\n",
    "\n",
    "colonnes = [\n",
    "    'plan_type_basic', 'plan_type_enterprise', 'plan_type_premium', 'plan_type_standard',\n",
    "    'channel_call_center', 'channel_mobile_app', 'channel_partner_api', 'channel_web'\n",
    "]\n",
    "\n",
    "# Conversion True -> 1, False -> 0\n",
    "df_train[colonnes] = df_train[colonnes].astype(int)\n",
    "df_test[colonnes] = df_test[colonnes].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Résultat\n",
    "# =========================\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape: \", df_test.shape)\n",
    "\n",
    "df_train.to_csv(\"../6.Data/Yann_Process_train.csv\", index=False)\n",
    "df_test.to_csv(\"../6.Data/Yann_Process_test.csv\",  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
